{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-08-20T16:21:06.590366Z","iopub.status.busy":"2025-08-20T16:21:06.590154Z","iopub.status.idle":"2025-08-20T16:21:06.605553Z","shell.execute_reply":"2025-08-20T16:21:06.604940Z","shell.execute_reply.started":"2025-08-20T16:21:06.590348Z"},"trusted":true},"outputs":[],"source":["# Cell 1: Imports\n","import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Dropout, TimeDistributed,\n","                                     LSTM, GRU, Conv3D, MaxPooling3D, BatchNormalization)\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-08-20T16:21:06.607317Z","iopub.status.busy":"2025-08-20T16:21:06.606983Z","iopub.status.idle":"2025-08-20T16:21:06.620527Z","shell.execute_reply":"2025-08-20T16:21:06.619919Z","shell.execute_reply.started":"2025-08-20T16:21:06.607298Z"},"trusted":true},"outputs":[],"source":["# Cell 2: Data settings and processing\n","\n","IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n","SEQUENCE_LENGTH = 20\n","\n","DATASET_DIR = \"/kaggle/input/shoplifting-videos-dataset/Shop DataSet\"\n","\n","CLASSES_LIST = [\"shop lifters\", \"non shop lifters\"]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-08-20T16:21:06.621262Z","iopub.status.busy":"2025-08-20T16:21:06.621071Z","iopub.status.idle":"2025-08-20T16:21:06.635784Z","shell.execute_reply":"2025-08-20T16:21:06.635088Z","shell.execute_reply.started":"2025-08-20T16:21:06.621243Z"},"trusted":true},"outputs":[],"source":["# Cell 3: Frame extraction function\n","def frames_extraction(video_path):\n","    frames_list = []\n","    \n","    video_reader = cv2.VideoCapture(video_path)\n","    \n","    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n","    \n","    skip_frames_window = max(int(video_frames_count / SEQUENCE_LENGTH), 1)\n","    \n","    for frame_counter in range(SEQUENCE_LENGTH):\n","        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n","        \n","        success, frame = video_reader.read()\n","        \n","        if not success:\n","            break\n","            \n","        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n","\n","        normalized_frame = resized_frame.astype(np.float32) / 255.0\n","        \n","        frames_list.append(normalized_frame)\n","        \n","    video_reader.release()\n","    return frames_list"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-08-20T16:21:06.636595Z","iopub.status.busy":"2025-08-20T16:21:06.636422Z","iopub.status.idle":"2025-08-20T16:21:06.645815Z","shell.execute_reply":"2025-08-20T16:21:06.645186Z","shell.execute_reply.started":"2025-08-20T16:21:06.636580Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["done\n"]}],"source":["'''\n","# Cell 4: Dataset creation function\n","def create_dataset():\n","    features = []\n","    labels = []\n","    \n","    for class_index, class_name in enumerate(CLASSES_LIST):\n","        print(f'Processing: {class_name}')\n","        \n","        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n","        \n","        for file_name in files_list:\n","            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n","            \n","            frames = frames_extraction(video_file_path)\n","            \n","            if len(frames) == SEQUENCE_LENGTH:\n","                features.append(frames)\n","                labels.append(class_index)\n","                \n","    features = np.asarray(features, dtype=np.float32)\n","    labels = np.array(labels, dtype=np.float32)\n","    \n","    return features, labels\n","'''\n","def create_dataset():\n","    features = []\n","    labels = []\n","    \n","    for class_index, class_name in enumerate(CLASSES_LIST):\n","        print(f'Processing: {class_name}')\n","        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n","        \n","        for file_name in files_list:\n","            \n","            if class_name == \"non shop lifters\" and file_name.endswith('_1.mp4'):\n","                print(f\"  - Filtering out duplicate file: {file_name}\")\n","                continue\n","            \n","            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n","            frames = frames_extraction(video_file_path)\n","            \n","            if len(frames) == SEQUENCE_LENGTH:\n","                features.append(frames)\n","                labels.append(class_index)\n","                \n","    features = np.asarray(features, dtype=np.float32)\n","    labels = np.array(labels, dtype=np.float32)\n","    \n","    return features, labels\n","\n","print(\"done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-20T16:21:06.646978Z","iopub.status.busy":"2025-08-20T16:21:06.646732Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing: shop lifters\n","Processing: non shop lifters\n","  - Filtering out duplicate file: shop_lifter_n_86_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_19_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_185_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_40_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_218_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_140_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_32_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_70_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_98_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_96_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_16_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_24_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_213_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_214_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_7_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_80_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_123_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_121_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_31_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_151_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_117_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_113_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_130_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_199_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_61_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_168_1.mp4\n","  - Filtering out duplicate file: videppppsss_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_52_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_179_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_162_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_191_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_75_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_63_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_54_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_202_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_53_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_165_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_79_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_158_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_27_1.mp4\n","  - Filtering out duplicate file: shop_lifter_n_194_1.mp4\n"]}],"source":["# Cell 5: Create and split dataset\n","features, labels = create_dataset()\n","\n","one_hot_encoded_labels = to_categorical(labels)\n","\n","features_train, features_test, labels_train, labels_test = train_test_split(\n","    features, one_hot_encoded_labels, test_size=0.2, shuffle=True, random_state=42)\n","\n","print(\"-----------------------------------------\")\n","print(f\"Train Data Shape {features_train.shape}\")\n","print(f\"Test Data Shape {features_test.shape}\")\n","print(\"-----------------------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Cell 6: Model creation functions\n","def create_conv_lstm_model():\n","\n","    base_model = VGG16(weights='imagenet', include_top=False, \n","                       input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n","    \n","    base_model.trainable = False\n","\n","    model = Sequential()\n","    model.add(TimeDistributed(base_model, input_shape=(SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n","    model.add(TimeDistributed(Flatten()))\n","    \n","    model.add(LSTM(64))\n","    \n","    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n","    \n","    model.summary()\n","    return model\n","\n","\n","def create_3d_cnn_model():\n","\n","    model = Sequential()\n","    \n","    model.add(Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu', padding='same',\n","                     input_shape=(SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n","    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n","    model.add(BatchNormalization())\n","    \n","    model.add(Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu', padding='same'))\n","    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n","    model.add(BatchNormalization())\n","\n","    model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu', padding='same'))\n","    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n","    model.add(BatchNormalization())\n","    \n","    model.add(Flatten())\n","    \n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n","    \n","    model.summary()\n","    return model\n","\n","\n","#def create_transformer_model():"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Cell 7: Model training and evaluation\n","\n","model = create_conv_lstm_model()\n","#model = create_3d_cnn_model()\n","# model = create_transformer_model()\n","\n","model.compile(optimizer='adam', \n","              loss='categorical_crossentropy', \n","              metrics=['accuracy'])\n","\n","\n","checkpoint_path = \"best_shoppplifting_model.h5\"\n","checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n","                             monitor='val_accuracy',\n","                             verbose=1,\n","                             save_best_only=True,\n","                             mode='max')\n","\n","\n","history = model.fit(features_train, labels_train, \n","                    epochs=30, \n","                    batch_size=4, \n","                    shuffle=True, \n","                    validation_split=0.2,\n","                    callbacks=[checkpoint])\n","\n","\n","model_evaluation_history = model.evaluate(features_test, labels_test)\n","model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n","\n","print(f\"Accuracy: {model_evaluation_accuracy * 100:.2f}%\")\n","print(f\"Loss: {model_evaluation_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Cell 8: Plotting functions\n","def plot_metric(history, metric_name, title):\n","    plt.plot(history.history[metric_name], label='Training ' + metric_name)\n","    plt.plot(history.history['val_' + metric_name], label='Validation ' + metric_name)\n","    plt.title(title)\n","    plt.ylabel(metric_name)\n","    plt.xlabel('Epoch')\n","    plt.legend()\n","    plt.show()\n","\n","plot_metric(history, 'accuracy', 'Model Accuracy')\n","\n","plot_metric(history, 'loss', 'Model Loss')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Cell 8: Plotting functions\n","def plot_metric(history, metric_name, title):\n","    plt.plot(history.history[metric_name], label='Training ' + metric_name)\n","    plt.plot(history.history['val_' + metric_name], label='Validation ' + metric_name)\n","    plt.title(title)\n","    plt.ylabel(metric_name)\n","    plt.xlabel('Epoch')\n","    plt.legend()\n","    plt.show()\n","\n","plot_metric(history, 'accuracy', 'Model Accuracy')\n","\n","plot_metric(history, 'loss', 'Model Loss')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":8009813,"sourceId":12674718,"sourceType":"datasetVersion"}],"dockerImageVersionId":31091,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"}},"nbformat":4,"nbformat_minor":4}
